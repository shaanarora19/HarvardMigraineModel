{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-qWgympVdPC"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxekI0zzVsWJ",
        "outputId": "0f8a99fd-773e-4782-becc-b2a7324327fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu5c0HDHV9Ch",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "e7d1897c-e18f-42e2-be56-3c16a0fe757e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-105b95657fca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfolders_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolders_all\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfolder\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolders_all\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolders_valid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, population, k)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Sample larger than population or is negative\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0msetsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m        \u001b[0;31m# size of a small set minus size of an empty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
          ]
        }
      ],
      "source": [
        "IMG_FOLDER = \"/content/drive/My Drive/HVD_APP/data/\"\n",
        "#IMG_FOLDER = \"/content/drive/My Drive/PD/output3/\"\n",
        "folders_all = glob.glob(IMG_FOLDER + \"/*\")\n",
        "\n",
        "print(len(folders_all))\n",
        "\n",
        "folders_valid = random.sample(folders_all,300)\n",
        "\n",
        "folders = [folder for folder in folders_all if folder not in folders_valid]\n",
        "random.shuffle(folders)\n",
        "\n",
        "def rand_img():\n",
        "  cc=0\n",
        "  while cc<len(folders):\n",
        "    folder = folders[cc]\n",
        "    y = random.randint(0,1)\n",
        "    imgs = np.zeros((128*2, 128*2))\n",
        "    flip = random.random()\n",
        "    img_front = np.array(Image.open(folder + \"/front.tif\"))\n",
        "    img_back =np.array(Image.open(folder + \"/back.tif\"))\n",
        "    img_left =np.array(Image.open(folder + \"/left.tif\"))\n",
        "    img_right =np.array(Image.open(folder + \"/right.tif\"))\n",
        "    if flip> 0.5:\n",
        "      imgs[0:128, 0*128:(0+1)*128] = np.flip(img_front, axis = 1)\n",
        "      imgs[0:128, 1*128:(1+1)*128] = np.flip(img_back, axis = 1)\n",
        "      imgs[128:256, 0*128:(0+1)*128] = np.flip(img_right, axis = 1)\n",
        "      imgs[128:256, 1*128:(1+1)*128] = np.flip(img_left, axis = 1)\n",
        "    else:\n",
        "      imgs[0:128, 0*128:(0+1)*128] = img_front\n",
        "      imgs[0:128, 1*128:(1+1)*128] = img_back\n",
        "      imgs[128:256, 0*128:(0+1)*128] = img_left\n",
        "      imgs[128:256, 1*128:(1+1)*128] = img_right\n",
        "    imgs = np.reshape(imgs, (1, 256, 256, 1))\n",
        "    imgs = np.clip(imgs, 0, 255)\n",
        "    y = np.load(folder + \"/out.npy\")\n",
        "    cc = cc+1\n",
        "\n",
        "    yield (imgs/255), np.array([y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X59NIVhZwsTm"
      },
      "outputs": [],
      "source": [
        "print(len(folders_all))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vU-oy7-gZriN"
      },
      "outputs": [],
      "source": [
        "ds_series = tf.data.Dataset.from_generator(\n",
        "    rand_img, \n",
        "    output_types=(tf.float32, tf.int32), \n",
        "    output_shapes=((1, 256, 256, 1), (1, 8)))\n",
        "ds_series.batch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OscFpmmpe-O3"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(ds_series.take(1)))\n",
        "plt.figure(figsize = (5,5))\n",
        "plt.imshow(x[0,:, :, 0], interpolation='nearest', cmap='gray')\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2LdEaWkjK11"
      },
      "outputs": [],
      "source": [
        "def getModel(input_shape):\n",
        "  model = Sequential()\n",
        "  \n",
        "  model.add(Input(shape = input_shape))\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation=tf.nn.leaky_relu, padding=\"same\")) \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #128, 128\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation=tf.nn.leaky_relu, padding=\"same\")) \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #64, 64\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation=tf.nn.leaky_relu, padding=\"same\")) \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) # 32, 32\n",
        "  model.add(Conv2D(256, kernel_size=(3, 3), activation=tf.nn.leaky_relu, padding=\"same\")) \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #16, 16\n",
        "  model.add(Conv2D(512, kernel_size=(3, 3), activation=tf.nn.leaky_relu, padding=\"same\")) \n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #8, 8\n",
        "  model.add(Conv2D(512, kernel_size=(3, 3), activation=tf.nn.leaky_relu, padding=\"same\")) # maybe change this value to be 1024\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2))) #4, 4\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(50, activation='relu'))\n",
        "  #model.add(Dense(3, activation='softmax'))\n",
        "  model.add(Dense(8, activation='sigmoid'))\n",
        "  #model.compile(optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr = 0.00001), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "  model.build()\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PJd2cizjUpy"
      },
      "outputs": [],
      "source": [
        "model = getModel((256, 256, 1))\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXjN26N0kPhW"
      },
      "outputs": [],
      "source": [
        "filepath=\"/content/drive/My Drive/PD/model_8_classes_3/weights/weights-improvement-{epoch:02d}.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "logs = tf.keras.callbacks.TensorBoard(log_dir='/content/drive/My Drive/PD/model_8_classes_3/logs')\n",
        "early = tf.keras.callbacks.EarlyStopping(patience=100, monitor = \"val_accuracy\")\n",
        "update = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.8, patience=10, min_lr=0.0001)\n",
        "callbacks_list = [checkpoint, logs, early, update]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM_DiZLbZBP_"
      },
      "outputs": [],
      "source": [
        "#model.load_weights(\"/content/drive/MyDrive/PD/model_8_classes_3/weights/weights-improvement-01.hdf5\")\n",
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "with open('/content/drive/My Drive/HVD_APP/classifier.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeAj40dYqyV3"
      },
      "outputs": [],
      "source": [
        "x_val = np.zeros((len(folders_valid), 256, 256, 1))\n",
        "y_val = np.zeros((len(folders_valid), 8))\n",
        "\n",
        "ii= 0\n",
        "for folder in folders_valid:\n",
        "  y_val[ii,:] = np.load(folder + \"/out.npy\")\n",
        "  for view_ in [[\"/front.tif\", 0, 0], [\"/back.tif\", 0, 1], [\"/left.tif\", 1,0], [\"/right.tif\", 1, 1]]:\n",
        "    row = view_[1]\n",
        "    col = view_[2]\n",
        "    view = view_[0]\n",
        "    img = np.array(Image.open(folder + view))/255\n",
        "    x_val[ii, row*128: row*128+128, col*128: col*128 + 128, 0] = img     \n",
        "  ii = ii+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3ZaSpG2vHTU"
      },
      "outputs": [],
      "source": [
        "folders_train = random.sample(folders,300)\n",
        "x_train = np.zeros((len(folders_train), 256, 256, 1))\n",
        "y_train = np.zeros((len(folders_train), 8))\n",
        "\n",
        "ii= 0\n",
        "for folder in folders_train:\n",
        "  y_train[ii,:] = np.load(folder + \"/out.npy\")\n",
        "  for view_ in [[\"/front.tif\", 0, 0], [\"/back.tif\", 0, 1], [\"/left.tif\", 1,0], [\"/right.tif\", 1, 1]]:\n",
        "    row = view_[1]\n",
        "    col = view_[2]\n",
        "    view = view_[0]\n",
        "    img = np.array(Image.open(folder + view))/255\n",
        "    x_train[ii, row*128: row*128+128, col*128: col*128 + 128, 0] = img    \n",
        "  ii = ii+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fiKnX0nrXIa"
      },
      "outputs": [],
      "source": [
        "x_plt = np.concatenate((x_train[0:10, ...], x_train[-10::, ...], x_val[0:10, ...], x_val[-10::, ...]), axis = 0)\n",
        "y_plt = np.concatenate((y_train[0:10, ...], y_train[-10::, ...], y_val[0:10, ...], y_val[-10::, ...]), axis = 0)\n",
        "plt.figure(figsize=(64, 16))\n",
        "for i in range(40):\n",
        "  plt.subplot(2, 20, i + 1)\n",
        "  plt.imshow(np.clip(x_plt[i,:, :, 0],0,1), cmap = \"gray\")\n",
        "  if y_plt[i,0]==1:\n",
        "    title = \"aty\"\n",
        "  elif y_plt[i,1]==1:\n",
        "    title = \"num\"\n",
        "  elif y_plt[i,2]==1:\n",
        "    title = \"occ1\"\n",
        "  elif y_plt[i,3]==1:\n",
        "    title = \"occ2\"\n",
        "  elif y_plt[i,4]==1:\n",
        "    title = \"rhino\"\n",
        "  elif y_plt[i,5]==1:\n",
        "    title = \"temp1\"\n",
        "  elif y_plt[i,6]==1:\n",
        "    title = \"temp2\"\n",
        "  elif y_plt[i,7]==1:\n",
        "    title = \"frontal\"\n",
        "  plt.title(title)\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF1Tt9519jKm"
      },
      "outputs": [],
      "source": [
        "val_accuracy = []\n",
        "test_accuracy = []\n",
        "train_accuracy = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBr3rgElkfoG"
      },
      "outputs": [],
      "source": [
        "#val_accuracy = []\n",
        "#test_accuracy = []\n",
        "#train_accuracy = []\n",
        "plt.figure()\n",
        "for ii in range(25):\n",
        "  model.fit(rand_img(), validation_data = [x_val, y_val], steps_per_epoch = len(folders), callbacks=callbacks_list, epochs=1)\n",
        "  train_accuracy.append(accuracy_score(model.predict(x_train)>0.5, y_train))\n",
        "  val_accuracy.append(accuracy_score(model.predict(x_val)>0.5, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x__Lyb9uw4n"
      },
      "outputs": [],
      "source": [
        "  plt.figure()\n",
        "  plt.plot(val_accuracy, label = \"val\")\n",
        "  plt.plot(train_accuracy, label = \"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28QDrjVvHvKy"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_plt = x_val[0:60, ...]\n",
        "y_plt = y_val[0:60, ...]\n",
        "y_pred = model.predict(x_val)>0.5\n",
        "plt.figure(figsize=(64, 16))\n",
        "for i in range(60):\n",
        "  plt.subplot(3, 20, i + 1)\n",
        "  plt.imshow(x_plt[i,:, :, 0], cmap = \"gray\")\n",
        "  if y_plt[i,0]==1:\n",
        "    title = \"aty\"\n",
        "  elif y_plt[i,1]==1:\n",
        "    title = \"num\"\n",
        "  elif y_plt[i,2]==1:\n",
        "    title = \"occ1\"\n",
        "  elif y_plt[i,3]==1:\n",
        "    title = \"occ2\"\n",
        "  elif y_plt[i,4]==1:\n",
        "    title = \"rhino\"\n",
        "  elif y_plt[i,5]==1:\n",
        "    title = \"temp1\"\n",
        "  elif y_plt[i,6]==1:\n",
        "    title = \"temp2\"\n",
        "  elif y_plt[i,7]==1:\n",
        "    title = \"frontal\"\n",
        "\n",
        "  if y_pred[i,0]==1:\n",
        "    title = title +\"/aty\"\n",
        "  elif y_pred[i,1]==1:\n",
        "    title = title +\"/num\"\n",
        "  elif y_pred[i,2]==1:\n",
        "    title = title +\"/occ1\"\n",
        "  elif y_pred[i,3]==1:\n",
        "    title = title +\"/occ2\"\n",
        "  elif y_pred[i,4]==1:\n",
        "    title = title +\"/rhino\"\n",
        "  elif y_pred[i,5]==1:\n",
        "    title = title +\"/temp1\"\n",
        "  elif y_pred[i,6]==1:\n",
        "    title = title +\"/temp2\"\n",
        "  elif y_pred[i,7]==1:\n",
        "    title = title +\"/frontal\"\n",
        "  plt.title(title)\n",
        "  plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKeTITQH2871"
      },
      "outputs": [],
      "source": [
        "#y_pred = np.array(model.predict(x_val)>0.5).astype(np.uint8)\n",
        "\n",
        "right = (np.array(y_val) == y_pred)\n",
        "rec = np.logical_and(right, y_val)\n",
        "right_guess = np.logical_and(right, y_pred)\n",
        "\n",
        "\n",
        "print([\"aty\", \"num\", \"occ1\", \"occ2\", \"rhino\", \"temp1\", \"temp2\", \"frontal\"])\n",
        "print(\"N: \")\n",
        "print(np.sum(y_val, axis = 0))\n",
        "print(\"Accuracy: \")\n",
        "print(np.sum(right, axis =0)/300)\n",
        "print(\"Sensitivity\")\n",
        "print(np.sum(rec, axis =0)/np.sum(y_val, axis = 0))\n",
        "print(\"Likelihood\")\n",
        "print(np.sum(right_guess, axis =0)/np.sum(y_pred, axis = 0))\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}